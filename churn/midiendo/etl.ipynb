{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sites a medir long: ''\n",
      "SIN DATOS LONG\n",
      "--------------- Ready metrics long\n",
      "Sites a medir short: 'MLC','MLA','MLB','MLM'\n",
      "--------------- Ready short queries\n",
      "--------------- Ready short metrics\n",
      "--------------- Ready cuponeros bkp\n",
      "{\"response status\": \"200\", \"response\": \"Hyper publicado en tableau con LUID: 7825f08a-3a22-4b98-9ca2-5f4ce1d1424f \", \"log_id\": 0, \"job_name\": \"c466f0c4-c73e-43d1-a638-04ab5ea9305f\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "# !pip install scikit-learn==0.23\n",
    "\n",
    "    import datetime\n",
    "    import os\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    import s3fs\n",
    "\n",
    "    import numpy as np\n",
    "    from melitk.fda import workspace\n",
    "\n",
    "    from mktutils.google_cloud import BigQuery\n",
    "    import mktutils.substatus as subs\n",
    "    import os\n",
    "    import base64\n",
    "\n",
    "    import datetime\n",
    "    from datetime import timedelta\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    from pytz import timezone\n",
    "\n",
    "    import boto3\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.download_file(\"fury-data-apps\", \"marketing-utils/pzenone/utils.py\",\"utils.py\")\n",
    "    import sys\n",
    "    sys.path.append(os.path.dirname(os.path.expanduser(\".\")))\n",
    "    sys.path.append(os.path.dirname(os.path.expanduser(\"./utils.py\")))\n",
    "    import utils\n",
    "\n",
    "    from causalml.inference.meta import LRSRegressor\n",
    "\n",
    "    from utils_churn import tmp_table_q,tools_q,covariates_q,preds_q,envios_q,rates_q,presupuesto_q,cambio_q,resu_short_q,cambio2_q,inc_metrics,table_persuadidos\n",
    "\n",
    "    if(os.environ[\"SECRET_DEBUG\"] == \"True\"):\n",
    "        sys.exit(0)\n",
    "        \n",
    "    TAKE_RATE={\n",
    "        \"MLA\":0.095,\n",
    "        \"MLM\":0.11,\n",
    "        \"MLC\":0.08,\n",
    "        \"MCO\":0.102,\n",
    "        \"MLB\":0.148\n",
    "    }\n",
    "\n",
    "    today = datetime.datetime.now(timezone('America/Argentina/Buenos_Aires'))\n",
    "    lu_day = today - timedelta(days = 9) # corre el juevs y busca el marte de la semana pasada\n",
    "    lu_day = lu_day.strftime(\"%Y-%m-%d\") # martes\n",
    "\n",
    "    sites = [\"MLA\",\"MLM\",\"MLB\",\"MCO\",\"MLC\"]\n",
    "    sites_str_ = \"','\".join(sites)\n",
    "    sites_str_generico = \"'\" + sites_str_ + \"'\"\n",
    "\n",
    "    # datetime.datetime.now(timezone('America/Argentina/Buenos_Aires'))\n",
    "\n",
    "    teradata_user = os.environ['SECRET_TERADATA_USER_LDAP']\n",
    "    teradata_pass = os.environ['SECRET_TERADATA_PASS_LDAP']\n",
    "\n",
    "    AUTH_BIGQUERY = base64.b64decode(os.environ[\"SECRET_MODELLING_BIGQUERY\"])\n",
    "    bq = BigQuery(AUTH_BIGQUERY)\n",
    "\n",
    "    sbs = subs.Substatus(AUTH_BIGQUERY) # suscribo en job monitor\n",
    "    sbs.subscriber('start',\"ALL\" , \"ML\", \"CHURN\", \"MIDIENDO\")\n",
    "\n",
    "    bq.execute(tmp_table_q(lu_day,sites_str_generico)).result() # temporal con sents por site\n",
    "\n",
    "    # En caso que falle la tabla de notifications de BQ\n",
    "    #     teradata_user = os.environ['SECRET_TERADATA_USER_LDAP']\n",
    "    #     teradata_pass = os.environ['SECRET_TERADATA_PASS_LDAP']\n",
    "    #     tera_ldap = utils.connection(teradata_user,\"Clave.13\",conector=\"teradata\", type_con = \"ldap\")\n",
    "    #     from utils_churn import temp_table_q_tera\n",
    "    #     users_site = temp_table_q_tera(lu_day,\"MCO\",\"MCO_ML_PUSHML_AO_ALL_X_ACT_ALL_CHURNCUPON-12K_DEFAULT\",bq,tera_ldap)\n",
    "\n",
    "    sites_sent = bq.execute_response(\"select sit_site_id from meli-marketing.TEMP45.PZ_SENTS_CHURN where event_type = 'sent' group by 1 having count(1) > 1000\").sit_site_id.values\n",
    "    sites_str = \"','\".join(sites_sent)\n",
    "    sites_str = \"'\" + sites_str + \"'\"\n",
    "    print(\"Sites a medir long:\", sites_str)\n",
    "\n",
    "    if(len(sites_sent) > 0):\n",
    "        tools = bq.execute_response(tools_q(sites_str)) # tool ids de churn\n",
    "        tools = \",\".join(tools.CAMPAIGN_ID.astype(str).values)\n",
    "\n",
    "        bq.execute(table_persuadidos(lu_day,sites_str,tools)).result()\n",
    "        covariates = bq.execute_response(covariates_q()) # genero covariables para causal inference\n",
    "        print(\"--------------- Ready covariates\")\n",
    "\n",
    "        preds = bq.execute_response(preds_q(sites_str,str(6))) # traigo forecast 90 d\n",
    "        preds = preds.rename(columns = {\"user_id\":\"CUS_CUST_ID\",\"sit_site_id\":\"SIT_SITE_ID\"})\n",
    "        preds.CUS_CUST_ID = preds.CUS_CUST_ID.astype(int)\n",
    "        print(preds.shape)\n",
    "\n",
    "        # puede fallar el forecast y faltar algun site, de ser asi me traigo el dia anterior\n",
    "        pending_site = [x for x in sites_sent if x not in preds[\"SIT_SITE_ID\"].unique()]\n",
    "\n",
    "        pending_sites_str = \"','\".join(pending_site)\n",
    "        pending_sites_str = \"'\" + pending_sites_str + \"'\"\n",
    "\n",
    "        if(len(pending_site) > 0):\n",
    "            preds2 = bq.execute_response(preds_q(pending_sites_str,str(5)))\n",
    "\n",
    "            preds2 = preds2.rename(columns = {\"user_id\":\"CUS_CUST_ID\",\"sit_site_id\":\"SIT_SITE_ID\"})\n",
    "            preds2.CUS_CUST_ID = preds2.CUS_CUST_ID.astype(int)\n",
    "            preds2 = preds2[[\"CUS_CUST_ID\",\"SIT_SITE_ID\",\"gmv_pred\",\"freq_pred\"]]\n",
    "            preds = preds.append(preds2[[\"CUS_CUST_ID\",\"SIT_SITE_ID\",\"gmv_pred\",\"freq_pred\"]],ignore_index=True)\n",
    "\n",
    "        pend = [x for x in sites_sent if x not in preds[\"SIT_SITE_ID\"].unique()]\n",
    "        if len(pend) > 0:\n",
    "            print(\"Quedan sites pendientes!!: \", pend)\n",
    "            raise(\"Faltan sites en tabla forecast\")\n",
    "\n",
    "        # Genero dataset de covariables\n",
    "        preds = preds.dropna()\n",
    "        users_all = pd.merge(covariates, preds[[\"CUS_CUST_ID\",\"SIT_SITE_ID\",\"gmv_pred\",\"freq_pred\"]].drop_duplicates(subset=[\"CUS_CUST_ID\",\"SIT_SITE_ID\"]),on=[\"CUS_CUST_ID\",\"SIT_SITE_ID\"])\n",
    "\n",
    "        users_all.CUS_CUST_ID = users_all.CUS_CUST_ID.astype(int)\n",
    "        users_all[\"freq_pred\"] = users_all[\"freq_pred\"].astype(float)\n",
    "        users_all[\"gmv_pred\"] = users_all[\"gmv_pred\"].astype(float)\n",
    "        users_all[\"GMV_7d\"] = users_all[\"GMV_7d\"].astype(float)\n",
    "        users_all[\"freq_7d\"] = users_all[\"freq_7d\"].astype(float)\n",
    "        users_all[\"GMV_MEAN\"] = users_all[\"GMV_MEAN\"].astype(float)\n",
    "\n",
    "        users_all[\"recency_date\"] = pd.to_datetime(users_all[\"recency_date\"],infer_datetime_format=True,errors = \"coerce\")\n",
    "        dia_push = users_all[\"recency_date\"].max()\n",
    "        users_all[\"recency_date\"] = (dia_push  - users_all[\"recency_date\"])/np.timedelta64(1, \"D\")\n",
    "        users_all[\"recency\"] = pd.to_datetime(users_all[\"recency\"],infer_datetime_format=True,errors = \"coerce\")\n",
    "        users_all[\"recency\"] = (dia_push  - users_all[\"recency\"])/np.timedelta64(1, \"D\")\n",
    "        users_all[\"first_purchase_window\"] = pd.to_datetime(users_all[\"first_purchase_window\"],infer_datetime_format=True,errors = \"coerce\")\n",
    "        users_all[\"first_purchase_window\"] = (dia_push  - users_all[\"first_purchase_window\"])/np.timedelta64(1, \"D\")\n",
    "\n",
    "        users_all.recency_date = users_all.recency_date.fillna(-10)\n",
    "        users_all = users_all.fillna(0)\n",
    "\n",
    "        users_all[\"freq_pred\"] = users_all[\"freq_pred\"].astype(float)\n",
    "        users_all[\"gmv_pred\"] = users_all[\"gmv_pred\"].astype(float)\n",
    "\n",
    "        users_all[\"freq_pred\"] = users_all[[\"freq_pred\",\"freq_7d\"]].sum(axis = 1)\n",
    "        users_all[\"gmv_pred\"] = users_all[[\"gmv_pred\",\"GMV_7d\"]].sum(axis = 1)\n",
    "\n",
    "        resu_envios = bq.execute_response(envios_q())## Short term pasado\n",
    "        resu_envios.GRUPO = resu_envios.GRUPO.replace({\"sent\":\"TG\",\"control\":\"CG\"})\n",
    "\n",
    "        rates = bq.execute_response(rates_q(lu_day,sites_str) )## Short term pasado\n",
    "\n",
    "        presupuesto = bq.execute_response(presupuesto_q(lu_day,sites_str))\n",
    "        presupuesto[\"AMOUNT\"] = presupuesto[\"AMOUNT\"].astype(float)\n",
    "        print(presupuesto)\n",
    "\n",
    "        cambio = bq.execute_response(cambio_q())\n",
    "        cambio[\"CCO_TC_VALUE\"] = cambio[\"CCO_TC_VALUE\"].astype(float)\n",
    "\n",
    "        # genero df final con resultados de largo plazo\n",
    "        validos = users_all.drop_duplicates(subset=[\"NOTIFICATION_DATE\",\"SIT_SITE_ID\"])\n",
    "\n",
    "        resultados_finales = pd.DataFrame([])\n",
    "        for ind,line in validos.iterrows():\n",
    "            print(\"--------\",line[\"SIT_SITE_ID\"],\"--------\")\n",
    "            push_day = line[\"NOTIFICATION_DATE\"]\n",
    "            aux_users = users_all.loc[users_all.SIT_SITE_ID == line[\"SIT_SITE_ID\"]]\n",
    "            aux_cambio = cambio.loc[cambio.SIT_SITE_ID == line[\"SIT_SITE_ID\"]].CCO_TC_VALUE.values[0]\n",
    "            aux_presupuesto = presupuesto.loc[presupuesto.SIT_SITE_ID == line[\"SIT_SITE_ID\"]]\n",
    "            if(aux_presupuesto.shape[0] > 0): # si pincho la mkt tool ese dia\n",
    "                aux_presupuesto = aux_presupuesto.AMOUNT.values[0]\n",
    "            else:\n",
    "                print(\"Sin presupuesto en SITE\")\n",
    "                continue\n",
    "\n",
    "            inc_gmv,inc_revenue,inc_freq = inc_metrics(aux_users,aux_cambio,aux_presupuesto,TAKE_RATE)\n",
    "            print(inc_gmv,inc_revenue,inc_freq)\n",
    "\n",
    "            buyers_tg = resu_envios.loc[(resu_envios.GRUPO == \"TG\") & (resu_envios.SIT_SITE_ID == line[\"SIT_SITE_ID\"])].buyers.values[0]\n",
    "            buyers_cg = resu_envios.loc[(resu_envios.GRUPO == \"CG\") & (resu_envios.SIT_SITE_ID == line[\"SIT_SITE_ID\"])].buyers.values[0]\n",
    "            gasto = presupuesto.loc[presupuesto.SIT_SITE_ID == line[\"SIT_SITE_ID\"]][\"AMOUNT\"].values[0]\n",
    "            cambio_ = cambio.loc[cambio.SIT_SITE_ID == line[\"SIT_SITE_ID\"]][\"CCO_TC_VALUE\"].values[0]\n",
    "            sent_tg = rates.loc[(rates.EVENT_TYPE == \"sent\") & (rates.SIT_SITE_ID == line[\"SIT_SITE_ID\"])].cant.values[0]\n",
    "            sent_cg = rates.loc[(rates.EVENT_TYPE == \"control\") & (rates.SIT_SITE_ID == line[\"SIT_SITE_ID\"])].cant.values[0]\n",
    "            shown_ = rates.loc[(rates.EVENT_TYPE == \"shown\") & (rates.SIT_SITE_ID == line[\"SIT_SITE_ID\"])].cant.values[0]\n",
    "            open_ = rates.loc[(rates.EVENT_TYPE == \"open\") & (rates.SIT_SITE_ID == line[\"SIT_SITE_ID\"])].cant.values[0]\n",
    "\n",
    "            resultados = pd.DataFrame([{\"BUYERS_TG\":buyers_tg,\"BUYERS_CG\":buyers_cg,\"PERSUADIDOS\":users_all.loc[(users_all.SIT_SITE_ID == line[\"SIT_SITE_ID\"]) & (users_all.GRUPO == \"TG\")].shape[0],\"GASTO\":gasto,\n",
    "             \"TOTALES_CG\":sent_cg,\"TOTALES_TG\":sent_tg,\"SENT\":sent_tg,\"SHOWN\":shown_,\"OPEN\":open_,\n",
    "             \"CAMBIO\":cambio_,\"GMV_INC_PRED\":inc_gmv,\"REVENUE_INC_PRED\":inc_revenue,\"FREQ_INC_PRED\":inc_freq,\n",
    "             \"SITE\":line[\"SIT_SITE_ID\"],\"FECHA\":push_day}])[['SITE','FECHA','BUYERS_CG', 'BUYERS_TG', 'CAMBIO', 'FREQ_INC_PRED', 'GASTO',\n",
    "                                               'GMV_INC_PRED', 'OPEN', 'PERSUADIDOS', 'REVENUE_INC_PRED', 'SENT',\n",
    "                                               'SHOWN', 'TOTALES_CG', 'TOTALES_TG']]\n",
    "\n",
    "            resultados_finales = resultados_finales.append(resultados,ignore_index=True)\n",
    "        resultados_finales.to_csv(\"churn.csv\",index=False)\n",
    "\n",
    "\n",
    "        bq.execute(\"\"\"\n",
    "            DELETE FROM meli-marketing.MODELLING.PZ_ALL_EXPERIMENTS where FECHA = DATE'\"\"\"+lu_day+\"\"\"' and sit_site_id in(\"\"\"+sites_str+\"\"\") and iniciativa = 'CHURN';\n",
    "\n",
    "            INSERT INTO meli-marketing.MODELLING.PZ_ALL_EXPERIMENTS(CUS_CUST_ID,GRUPO,FECHA,INICIATIVA,SIT_SITE_ID)\n",
    "            (\n",
    "                SELECT CUS_CUST_ID,NULL as GRUPO,NOTIFICATION_DATE AS FECHA,'CHURN' as INICIATIVA,SIT_SITE_ID\n",
    "                FROM meli-marketing.TEMP45.PZ_TMP_PERSUADIDOS p\n",
    "                WHERE GRUPO = 'TG'\n",
    "            );\n",
    "\n",
    "        \"\"\").result()\n",
    "\n",
    "        bq.execute(\"DELETE FROM  meli-marketing.TEMP45.PZ_TMP_PERSUADIDOS WHERE 1=1\").result()\n",
    "        bq.execute(\"DELETE FROM  meli-marketing.TEMP45.PZ_SENTS_CHURN WHERE 1=1\").result()\n",
    "\n",
    "    else:\n",
    "        pd.DataFrame([],columns = ['SITE','FECHA','BUYERS_CG', 'BUYERS_TG', 'CAMBIO', 'FREQ_INC_PRED', 'GASTO',\n",
    "                                               'GMV_INC_PRED', 'OPEN', 'PERSUADIDOS', 'REVENUE_INC_PRED', 'SENT',\n",
    "                                               'SHOWN', 'TOTALES_CG', 'TOTALES_TG']).to_csv(\"churn.csv\",index=False)\n",
    "        print(\"SIN DATOS LONG\")\n",
    "\n",
    "    print(\"--------------- Ready metrics long\")\n",
    "\n",
    "    ######### Short term\n",
    "\n",
    "    lu_day = today - timedelta(days = 2) # corre los jueves el job, y busca los datos del martes\n",
    "    lu_day = lu_day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    sites_short = bq.execute_response(\"\"\"\n",
    "                select distinct sit_site_id\n",
    "                from meli-marketing.MKTPUBLIC.V_BT_PUSH_NOTIFICATION_EVENT b\n",
    "                WHERE SENT_DATE = DATE'\"\"\"+lu_day+\"\"\"' and b.sit_site_id in (\"\"\"+sites_str_generico+\"\"\")\n",
    "                    AND lower(BATCH_ID) like '%churncupon%' and EVENT_TYPE in ('sent')\n",
    "                    and APP = 'mercadolibre'\n",
    "        \"\"\").sit_site_id.values\n",
    "\n",
    "    if(len(sites_short) > 0):\n",
    "        sites_str = \"','\".join(sites_short)\n",
    "        sites_str = \"'\" + sites_str + \"'\"\n",
    "        print(\"Sites a medir short:\", sites_str)\n",
    "\n",
    "        tools = bq.execute_response(tools_q(sites_str)) # tool ids de churn\n",
    "        tools = \",\".join(tools.CAMPAIGN_ID.astype(str).values)\n",
    "\n",
    "        bq.execute(tmp_table_q(lu_day,sites_str)).result()\n",
    "\n",
    "        # En caso que falle la tabla de notifications de BQ\n",
    "    #         teradata_user = os.environ['SECRET_TERADATA_USER_LDAP']\n",
    "    #         teradata_pass = os.environ['SECRET_TERADATA_PASS_LDAP']\n",
    "    #         tera_ldap = utils.connection(teradata_user,teradata_pass,conector=\"teradata\", type_con = \"ldap\")\n",
    "    #         from utils_churn import temp_table_q_tera\n",
    "    #         users_site = temp_table_q_tera(lu_day,\"MCO\",\"MCO_ML_PUSHML_AO_ALL_X_ACT_ALL_CHURNCUPON-12K_DEFAULT\",bq,tera_ldap)\n",
    "\n",
    "        resu_envio_short = bq.execute_response(resu_short_q(lu_day,sites_str,tools))\n",
    "\n",
    "        print(\"--------------- Ready short queries\")\n",
    "\n",
    "        cambio = bq.execute_response(cambio2_q(lu_day,sites_str))\n",
    "        cambio[\"CCO_TC_VALUE\"] = cambio[\"CCO_TC_VALUE\"].astype(float)\n",
    "\n",
    "        # Genero df de corto plazo\n",
    "        site_resu = pd.DataFrame([])\n",
    "        for site in resu_envio_short.sit_site_id.unique():\n",
    "            buyers_tg = resu_envio_short.loc[(resu_envio_short.EVENT_TYPE == \"sent\") & (resu_envio_short[\"sit_site_id\"] == site)][\"BUYERS\"].values[0]\n",
    "            buyers_cg = resu_envio_short.loc[(resu_envio_short.EVENT_TYPE == \"control\") & (resu_envio_short[\"sit_site_id\"] == site)][\"BUYERS\"].values[0]\n",
    "            tot_tg = resu_envio_short.loc[(resu_envio_short.EVENT_TYPE == \"sent\") & (resu_envio_short[\"sit_site_id\"] == site)][\"AMT\"].values[0]\n",
    "            tot_cg = resu_envio_short.loc[(resu_envio_short.EVENT_TYPE == \"control\") & (resu_envio_short[\"sit_site_id\"] == site)][\"AMT\"].values[0]\n",
    "            shown_ = resu_envio_short.loc[(resu_envio_short.EVENT_TYPE == \"shown\") & (resu_envio_short[\"sit_site_id\"] == site)][\"AMT\"].values[0]\n",
    "            open_ = resu_envio_short.loc[(resu_envio_short.EVENT_TYPE == \"open\") & (resu_envio_short[\"sit_site_id\"] == site)][\"AMT\"].values[0]\n",
    "            cambio_ = cambio.loc[cambio.SIT_SITE_ID == site]\n",
    "            gasto = resu_envio_short.loc[(resu_envio_short.EVENT_TYPE == \"sent\") & (resu_envio_short[\"sit_site_id\"] == site)][\"AMOUNT\"].values[0]\n",
    "\n",
    "            resultados = pd.DataFrame([{\"BUYERS_TG\":buyers_tg,\"BUYERS_CG\":buyers_cg,\"PERSUADIDOS\":np.nan,\"GASTO\":gasto,\n",
    "                 \"TOTALES_TG\":tot_tg,\"TOTALES_CG\":tot_cg,\"SENT\":tot_tg,\"SHOWN\":shown_,\"OPEN\":open_,\n",
    "                 \"CAMBIO\":cambio_.CCO_TC_VALUE.values[0],\"GMV_INC_PRED\":np.nan,\"REVENUE_INC_PRED\":np.nan,\"FREQ_INC_PRED\":np.nan,\n",
    "                 \"SITE\":site,\"FECHA\":lu_day}])[['SITE','FECHA','BUYERS_CG', 'BUYERS_TG', 'CAMBIO', 'FREQ_INC_PRED', 'GASTO',\n",
    "                                                   'GMV_INC_PRED', 'OPEN', 'PERSUADIDOS', 'REVENUE_INC_PRED', 'SENT',\n",
    "                                                   'SHOWN', 'TOTALES_CG', 'TOTALES_TG']]\n",
    "\n",
    "            site_resu = site_resu.append(resultados,ignore_index=True)\n",
    "        site_resu.to_csv(\"churn_daily.csv\",index=False)\n",
    "\n",
    "        print(\"--------------- Ready short metrics\")\n",
    "\n",
    "        ### saco cuponeros\n",
    "        today = datetime.datetime.now(timezone('America/Argentina/Buenos_Aires'))\n",
    "\n",
    "        lu_day = today - timedelta(days = 2) # corre los jueves el job, y busca los datos del martes\n",
    "        fecha = lu_day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        bq.execute(\"\"\"\n",
    "\n",
    "            INSERT INTO `meli-marketing.MODELLING.PZ_AUTOMATION_PUSH` (user_id, my_payload, full_payload, fecha, iniciativa)\n",
    "            (\n",
    "                WITH PAGOS as(\n",
    "                      SELECT  pay.cus_cust_id_buy as CUS_CUST_ID,pay.SIT_SITE_ID\n",
    "                      FROM  `meli-bi-data.WHOWNER.BT_MP_PAY_PAYMENTS` as pay\n",
    "                      INNER JOIN `meli-bi-data.WHOWNER.BT_MKT_COUPON_V2` as cpn\n",
    "                          on pay.pay_payment_id = cpn.pay_payment_id\n",
    "                          and pay.cus_cust_id_buy = cpn.cus_cust_id_buy\n",
    "                          AND MKT_CPN_CREATION_DATE > DATE_SUB(CURRENT_DATE() ,INTERVAL 90 DAY)\n",
    "                          AND mkt_cpn_campaign_id in (\"\"\"+tools+\"\"\")\n",
    "                      WHERE\n",
    "                          pay.pay_status_code = 'approved'\n",
    "                          AND pay.SIT_SITE_ID in (\"\"\"+sites_str+\"\"\")\n",
    "                          AND pay_created_dt BETWEEN DATE'\"\"\"+fecha+\"\"\"' AND DATE_ADD(DATE'\"\"\"+fecha+\"\"\"' ,INTERVAL 1 DAY) \n",
    "                      GROUP BY 1,2\n",
    "                )\n",
    "                SELECT  CAST(CUS_CUST_ID as STRING) as user_id,\n",
    "                CAST(NULL as STRING) as my_payload,\n",
    "                CAST(NULL as STRING) as full_payload,\n",
    "                DATE'\"\"\"+fecha+\"\"\"' as FECHA,\n",
    "                SIT_SITE_ID || '-ML-CHURN' as INICIATIVA \n",
    "                FROM PAGOS p\n",
    "                WHERE NOT EXISTS(SELECT 1 FROM `meli-marketing.MODELLING.PZ_AUTOMATION_PUSH` c \n",
    "                                 WHERE SUBSTR(c.INICIATIVA,0,3) = p.SIT_SITE_ID \n",
    "                                      AND INICIATIVA like '%-ML-CHURN'\n",
    "                                      AND c.FECHA = DATE'\"\"\"+fecha+\"\"\"'\n",
    "                                 )\n",
    "            );\n",
    "        \"\"\").result()\n",
    "\n",
    "    else:\n",
    "        pd.DataFrame([],columns = ['SITE','FECHA','BUYERS_CG', 'BUYERS_TG', 'CAMBIO', 'FREQ_INC_PRED', 'GASTO',\n",
    "                                                   'GMV_INC_PRED', 'OPEN', 'PERSUADIDOS', 'REVENUE_INC_PRED', 'SENT',\n",
    "                                                   'SHOWN', 'TOTALES_CG', 'TOTALES_TG']).to_csv(\"churn_daily.csv\",index=False)\n",
    "        print(\"SIN DATOS SHORT\")\n",
    "\n",
    "    print(\"--------------- Ready cuponeros bkp\")\n",
    "\n",
    "    ####### Subo a Tableau\n",
    "    utils.my_download_file(\"s3://fury-data-apps/ltv-churn-ml/extracto.csv\", \"extracto.csv\")\n",
    "    extracto = pd.read_csv(\"extracto.csv\", delimiter=\"|\")\n",
    "\n",
    "    appender = pd.read_csv(\"churn.csv\")\n",
    "    aux = pd.merge(extracto,appender[[\"SITE\",\"FECHA\"]].assign(dummy = 1),on=[\"SITE\",\"FECHA\"],how=\"left\")\n",
    "    aux = aux.loc[aux.dummy != 1].drop([\"dummy\"],axis = 1)\n",
    "\n",
    "    extracto = aux.append(appender[aux.columns],ignore_index=True)\n",
    "\n",
    "    appender = pd.read_csv(\"churn_daily.csv\")\n",
    "    aux = pd.merge(extracto,appender[[\"SITE\",\"FECHA\"]].assign(dummy = 1),on=[\"SITE\",\"FECHA\"],how=\"left\")\n",
    "    aux = aux.loc[aux.dummy != 1].drop([\"dummy\"],axis = 1)\n",
    "\n",
    "    extracto = aux.append(appender[aux.columns],ignore_index=True)\n",
    "    extracto.to_csv(\"subirme.csv\",index=False,sep=\"|\")\n",
    "\n",
    "    utils.my_upload_file(\"subirme.csv\",\"s3://fury-data-apps/ltv-churn-ml/extracto.csv\")\n",
    "\n",
    "    # Subir a bucket de BI\n",
    "\n",
    "    sesion = boto3.session.Session()\n",
    "    client = sesion.client('s3',aws_access_key_id = os.environ[\"SECRET_S3_PUBLIC_ACCESS\"],  aws_secret_access_key = os.environ[\"SECRET_S3_PUBLIC_SECRET\"] )\n",
    "    client.upload_file(\"subirme.csv\",\"bi-public-data\", \"pzenone/CHURN_ML/tableau/subime.csv\")\n",
    "\n",
    "    import requests\n",
    "    url = 'http://internal.mercadolibre.com/bi/steps/tableau/createhyper'\n",
    "    payload = {\n",
    "               \"user\":\"pzenone\",\n",
    "               \"password\":\"Clave.01\",\n",
    "               \"site\":\"Marketplace\",\n",
    "               \"project\":\"Marketing\",\n",
    "               \"extractName\":\"PZ_Churn_Metrics\",\n",
    "               \"access\":os.environ[\"SECRET_S3_PUBLIC_ACCESS\"],\n",
    "               \"secret_key\":os.environ[\"SECRET_S3_PUBLIC_SECRET\"],\n",
    "               \"bucket\":\"bi-public-data\",\n",
    "               \"delimiter\":\"|\",\n",
    "               \"inputName\":\"pzenone/CHURN_ML/tableau/subime.csv\",\n",
    "               \"struct\":{\"struct\":{\"SITE\":\"text\",\"FECHA\":\"date\",\"BUYERS_CG\":\"big_int\",\"BUYERS_TG\":\"big_int\",\"CAMBIO\":\"double\",\n",
    "                                  \"FREQ_INC_PRED\":\"double\",\"GASTO\":\"double\",\"GMV_INC_PRED\":\"double\",\"OPEN\":\"big_int\",\n",
    "                                  \"PERSUADIDOS\":\"big_int\",\"REVENUE_INC_PRED\":\"double\",\"SENT\":\"big_int\",\"SHOWN\":\"big_int\",\n",
    "                                  \"TOTALES_CG\":\"big_int\",\"TOTALES_TG\":\"big_int\"}} \n",
    "    }\n",
    "\n",
    "    x = requests.post(url, json = payload)\n",
    "    print(x.text)\n",
    "\n",
    "    if(x.json()[\"response status\"] != \"200\"):\n",
    "        raise(\"Error publicando en tableau\")\n",
    "\n",
    "    sbs.subscriber('end',\"ALL\" , \"ML\", \"CHURN\", \"MIDIENDO\")\n",
    "    \n",
    "except Exception as inst:\n",
    "    print(type(inst))    \n",
    "    print(inst.args)    \n",
    "    print(inst)  \n",
    "    \n",
    "    import boto3\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.download_file(\"fury-data-apps\", \"marketing-utils/pzenone/utils.py\",\"utils.py\")\n",
    "    import utils\n",
    "    \n",
    "    subject = 'Falla en Midiendo Churn'\n",
    "    body = 'Fallo la función de midiendo churn'\n",
    "    sub = utils.Substatus(\"\", mail_to='pedro.zenone@mercadolibre.com')\n",
    "    sub.send_alert(subject, body)\n",
    "    raise ValueError('Fuerzo error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
