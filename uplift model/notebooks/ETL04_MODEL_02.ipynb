{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is for:**\n",
    "1. Testing causalML.\n",
    "https://antonsruberts.github.io/causalml-test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.19.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (0.30.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install statsmodels --upgrade\n",
    "# !pip install scipy==1.5.4 \n",
    "# !pip install scikit-learn --upgrade\n",
    "# !pip install numpy\n",
    "# !pip install h5py\n",
    "# !pip install typing-extensions\n",
    "# !pip install wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, BaseSRegressor, BaseTRegressor\n",
    "from causalml.match import NearestNeighborMatch, MatchOptimizer, create_table_one\n",
    "from causalml.propensity import ElasticNetPropensityModel\n",
    "from causalml.dataset import *\n",
    "from causalml.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import causalml.dataset as data\n",
    "# dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = make_uplift_classification(n_samples=1000,\n",
    "#                            treatment_name=['control', 'treatment1'],\n",
    "#                            y_name='conversion',\n",
    "#                            n_classification_features=10,\n",
    "#                            n_classification_informative=5,\n",
    "#                            n_uplift_increase_dict={'treatment1': 4},\n",
    "#                            n_uplift_decrease_dict={'treatment1': 3},\n",
    "#                            delta_uplift_increase_dict={'treatment1': 0.1},\n",
    "#                            positive_class_proportion=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data using mode 1\n",
    "y, X, treatment, tau, b, e = synthetic_data(mode=1, n=10000, p=8, sigma=1.0)\n",
    "# tau: individual treatment effect\n",
    "# b: expected outcome\n",
    "# e: propensity of receiving treatment\n",
    "# y: outcome variable\n",
    "# X: covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready-to-use S-Learner using LinearRegression\n",
    "learner_s = LRSRegressor()\n",
    "ate_s = learner_s.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print(ate_s)\n",
    "print('ATE estimate: {:.03f}'.format(ate_s[0][0]))\n",
    "print('ATE lower bound: {:.03f}'.format(ate_s[1][0]))\n",
    "print('ATE upper bound: {:.03f}'.format(ate_s[2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBTRegressor() vs. BaseTRegressor(learner=XGBRegressor())\n",
    "# XGBTRegressor() = BaseTRegressor(learner=XGBRegressor()).\n",
    "# When you use BaseTregressor you can change the model to be used in the Two model approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready-to-use T-Learner using XGB\n",
    "learner_t = XGBTRegressor()\n",
    "ate_t = learner_t.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('Using the ready-to-use XGBTRegressor class')\n",
    "print(ate_t)\n",
    "\n",
    "# Calling the Base Learner class and feeding in XGB\n",
    "learner_t = BaseTRegressor(learner=XGBRegressor())\n",
    "ate_t = learner_t.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('\\nUsing the BaseTRegressor class and using XGB (same result):')\n",
    "print(ate_t)\n",
    "\n",
    "# Calling the Base Learner class and feeding in LinearRegression\n",
    "learner_t = BaseTRegressor(learner=LinearRegression())\n",
    "ate_t = learner_t.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print('\\nUsing the BaseTRegressor class and using Linear Regression (different result):')\n",
    "print(ate_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S Learner\n",
    "learner_s = LRSRegressor()\n",
    "cate_s = learner_s.fit_predict(X=X, treatment=treatment, y=y)\n",
    "\n",
    "# T Learner\n",
    "learner_t = BaseTRegressor(learner=XGBRegressor())\n",
    "cate_t = learner_t.fit_predict(X=X, treatment=treatment, y=y)\n",
    "\n",
    "# X Learner with propensity score input\n",
    "learner_x = BaseXRegressor(learner=XGBRegressor())\n",
    "cate_x = learner_x.fit_predict(X=X, treatment=treatment, y=y, p=e)\n",
    "\n",
    "# X Learner without propensity score input\n",
    "learner_x_no_p = BaseXRegressor(learner=XGBRegressor())\n",
    "cate_x_no_p = learner_x_no_p.fit_predict(X=X, treatment=treatment, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.subtract(tau , results[:,x]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "results = np.hstack([cate_s,cate_t,cate_x,cate_x_no_p])\n",
    "labels = {0: 'single model lr',1:'two model XGBoost-reg',2: 'x model XGBoost-re w/ e', 3:'x model XGBoost-re wo/ e'}\n",
    "A = []\n",
    "for x in range(4):\n",
    "    diff.append(np.subtract(tau , results[:,x]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize = (16,6))\n",
    "fig.subplots_adjust(hspace = 5)\n",
    "axs = axs.ravel()\n",
    "for x in np.arange(0,3,1):\n",
    "    y = results[:,x+1]\n",
    "    axs[x].hist(x = y,bins=100,alpha=0.4)\n",
    "    axs[x].vlines(x = results[:,0], ymin = 0 , ymax = 1000)\n",
    "    axs[x].set_title(f'{labels[x+1]} \\n mean: {np.round(np.mean(y),2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,4, figsize = (16,6))\n",
    "fig.subplots_adjust(hspace = 5)\n",
    "axs = axs.ravel()\n",
    "for x in range(4):\n",
    "    y = diff[x]\n",
    "    axs[x].hist(x = y,bins=100,alpha=0.4)\n",
    "    axs[x].set_title(f'{labels[x]} - \\n MAE: {np.round(np.mean(np.abs(y)),2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/uber/causalml/blob/master/examples/uplift_trees_with_synthetic_data.ipynb\n",
    "from causalml.inference.tree import UpliftTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, x_names = make_uplift_classification(n_samples=1000,\n",
    "                           treatment_name=['control', 'treatment1'],\n",
    "                           y_name='conversion',\n",
    "                           n_classification_features=10,\n",
    "                           n_classification_informative=5,\n",
    "                           n_uplift_increase_dict={'treatment1': 4},\n",
    "                           n_uplift_decrease_dict={'treatment1': 3},\n",
    "                           delta_uplift_increase_dict={'treatment1': 0.3},#<------------\n",
    "                           delta_uplift_decrease_dict={'treatment1': 0.1},                    \n",
    "                           positive_class_proportion=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and testing samples for model validation (next section)\n",
    "df_train, df_test = train_test_split(dataset, test_size=0.2, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = UpliftTreeClassifier(control_name='control')\n",
    "clf.fit(df_train[x_names].values,\n",
    "         treatment=df_train['treatment_group_key'].values,\n",
    "         y=df_train['conversion'].values)\n",
    "p = clf.predict(df_test[x_names].values,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(p, columns=clf.classes_)\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_res.treatment1 - df_res.control ).mean()#<------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_treatment = df_res.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_treatment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
