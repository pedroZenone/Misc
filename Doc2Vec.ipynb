{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from lifetimes.utils import summary_data_from_transaction_data\n",
    "import numpy as np\n",
    "import datetime\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "from lifetimes import ModifiedBetaGeoFitter\n",
    "from lifetimes import GammaGammaFitter\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import joblib\n",
    "import boto3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "config = tf.ConfigProto(device_count={\"CPU\": 20})\n",
    "keras.backend.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.layers import Dropout\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats.distributions import expon\n",
    "from keras.models import load_model\n",
    "import io\n",
    "import json\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_dataframe_to_csv_on_s3(df, path_s3):\n",
    "    import boto3\n",
    "    from io import StringIO\n",
    "    \"\"\" Write a dataframe to a CSV on S3 \"\"\"\n",
    "    a = path_s3.split('//')\n",
    "    b = a[1].split('/')\n",
    "    bucket = b[0]\n",
    "    c = path_s3.split(bucket+'/')\n",
    "    path = c[1]\n",
    "    \n",
    "    buffer = StringIO()\n",
    "    df.to_csv(buffer,index=False)\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_resource.Object(bucket, path).put(Body=buffer.getvalue())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/usr/local/lib/python3.5/site-packages/dask/dataframe/core.py:3966: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=(None, 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "/usr/local/lib/python3.5/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/usr/local/lib/python3.5/site-packages/dask/dataframe/core.py:3966: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=(None, 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "/usr/local/lib/python3.5/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/usr/local/lib/python3.5/site-packages/dask/dataframe/core.py:3966: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=(None, 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "/usr/local/lib/python3.5/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/usr/local/lib/python3.5/site-packages/dask/dataframe/core.py:3966: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=(None, 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "/usr/local/lib/python3.5/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/usr/local/lib/python3.5/site-packages/dask/dataframe/core.py:3966: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=(None, 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "visits = pd.read_csv(\"s3://fda-labs/ltv-ml/ML/summary_visitas_train.csv\")\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "for name in [\"doc2vec_20_20\",\"doc2vec_10_20\",\"doc2vec_20_12\",\"doc2vec_20_8\",\"doc2vec_32_20\"]:\n",
    "    \n",
    "    s3.download_file(\"fda-labs\", \"ltv-ml/Embedding/\"+name+\"/\"+name,name)\n",
    "    s3.download_file(\"fda-labs\", \"ltv-ml/Embedding/\"+name+\"/\"+name+\".docvecs.vectors_docs.npy\",\n",
    "                     name+\".docvecs.vectors_docs.npy\")\n",
    "\n",
    "    model = Doc2Vec.load(name)\n",
    "\n",
    "    # aplico vectorizacion\n",
    "    vector = dd.from_pandas(visits, npartitions=cpu_count()).apply(\n",
    "        lambda x: model.infer_vector(x.phrase.split(' ')),axis = 1).compute(scheduler='processes')\n",
    "\n",
    "    # trsnformo el resultado en df\n",
    "    vector = pd.DataFrame.from_records(np.array(vector)).head()\n",
    "    vector.columns = [name+\"_\"+str(x) for x in list(vector.columns)]\n",
    "\n",
    "    # le agrego el customer y guardo\n",
    "    vector[\"cust\"] = visits[\"cust\"]\n",
    "    _write_dataframe_to_csv_on_s3(vector,\"s3://fda-labs/ltv-ml/Embedding/preproc_Doc2vec/train_\"+name+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = pd.read_csv(\"s3://fda-labs/ltv-ml/ML/summary_visitas_test.csv\")\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "for name in [\"doc2vec_20_20\",\"doc2vec_10_20\",\"doc2vec_20_12\",\"doc2vec_20_8\",\"doc2vec_32_20\"]:\n",
    "    \n",
    "    s3.download_file(\"fda-labs\", \"ltv-ml/Embedding/\"+name+\"/\"+name,name)\n",
    "    s3.download_file(\"fda-labs\", \"ltv-ml/Embedding/\"+name+\"/\"+name+\".docvecs.vectors_docs.npy\",\n",
    "                     name+\".docvecs.vectors_docs.npy\")\n",
    "\n",
    "    model = Doc2Vec.load(name)\n",
    "\n",
    "    # aplico vectorizacion\n",
    "    vector = dd.from_pandas(visits, npartitions=cpu_count()).apply(\n",
    "        lambda x: model.infer_vector(x.phrase.split(' ')),axis = 1).compute(scheduler='processes')\n",
    "\n",
    "    # trsnformo el resultado en df\n",
    "    vector = pd.DataFrame.from_records(np.array(vector)).head()\n",
    "    vector.columns = [name+\"_\"+str(x) for x in list(vector.columns)]\n",
    "\n",
    "    # le agrego el customer y guardo\n",
    "    vector[\"cust\"] = visits[\"cust\"]\n",
    "    _write_dataframe_to_csv_on_s3(vector,\"s3://fda-labs/ltv-ml/Embedding/preproc_Doc2vec/test_\"+name+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
